{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f23043-efef-4286-ab4b-92f980a19c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36059b5-1620-4acc-a066-bade882e2da0",
   "metadata": {},
   "source": [
    "# Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "007d4fd0-a461-4502-a784-4ba993eb79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f39e8c24-463a-41f2-a678-b0d0207b3de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./cifardata', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifardata', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 클래스가 10개다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615cea3-5581-4404-995b-421b083cbd1f",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d7cce43-7ec1-449d-8417-840112abc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cf56055-c83e-47f0-89bf-b41903dc9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치에서 모델을 만드는 가장 기본적인 방법은 다음과 같다.\n",
    "\n",
    "class kenGwonNeuralNet(nn.Module): # 여기서 반드시 nn.Module을 상속 받아야 한다.\n",
    "    \n",
    "    def __init__(self): ## __init__()에서 내가 만들고자 하는 뉴럴넷의 구조를 적어주면 된다. pretrained model이 여기 들어와야 하는 것 같다.\n",
    "        super(kenGwonNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5* 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 분류하기 위한 클래스가 10개이기 때문에 아웃풋이 10개인 레이어를 이렇게 만들었다. \n",
    "\n",
    "    def forward(self, x): ## forward()에서 연산의 순서를 정의해준다. __init__()에서 만들어놓은 레이어들을 데이터 x에 대해서 어떻게 연산을 시킬 것인지를 적는 것이다.\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5) # 위에서 convolution레이어를 다 돌았으니 이제 flatten해서 선형 레이어에 넣어주기 위해서 torch.Tensor를 변환해주었다.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "myNN = kenGwonNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c80352a-08f7-4c52-a0c3-2a40f724dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kenGwonNeuralNet(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(myNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35f390-9b41-48a9-93fb-3ac3b0aa7e4c",
   "metadata": {},
   "source": [
    "# Implement the model with trainig set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c06a792-9fe6-4082-b8f1-55c6217a86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Loss function로 전형적인 분류문제를 위해 쓰이는 CrossEntropyLoss()를 사용하기로 함 \n",
    "optimizer = optim.SGD(myNN.parameters(), lr=0.001, momentum=0.9) # myNN.parameters() 이것을 통해 우리가 선언한 뉴럴넷의 구조가 옵티마이저에 들어가게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31290965-bb37-41f2-8823-9447092ba22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   200 loss: 0.164]\n",
      "[epoch: 1, batch:   400 loss: 0.162]\n",
      "[epoch: 1, batch:   600 loss: 0.163]\n",
      "[epoch: 1, batch:   800 loss: 0.160]\n",
      "[epoch: 1, batch:  1000 loss: 0.156]\n",
      "[epoch: 1, batch:  1200 loss: 0.158]\n",
      "[epoch: 2, batch:   200 loss: 0.154]\n",
      "[epoch: 2, batch:   400 loss: 0.146]\n",
      "[epoch: 2, batch:   600 loss: 0.151]\n",
      "[epoch: 2, batch:   800 loss: 0.150]\n",
      "[epoch: 2, batch:  1000 loss: 0.151]\n",
      "[epoch: 2, batch:  1200 loss: 0.150]\n",
      "[epoch: 3, batch:   200 loss: 0.144]\n",
      "[epoch: 3, batch:   400 loss: 0.142]\n",
      "[epoch: 3, batch:   600 loss: 0.142]\n",
      "[epoch: 3, batch:   800 loss: 0.143]\n",
      "[epoch: 3, batch:  1000 loss: 0.141]\n",
      "[epoch: 3, batch:  1200 loss: 0.143]\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "# 이 블럭이 실질적으로 학습이 일어나는 부분이다.\n",
    "\n",
    "for epoch in range(3):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data # batch 묶음으로 던져주기 때문에, 변수명을 복수형으로 써주는게 맞다. 위에서 batch를 8로 줬기 때문에, 이 한번의 for문에서 연산되는 이미지의 갯수는 8개이다.\n",
    "\n",
    "        optimizer.zero_grad() # 옵티마이저를 초기화 시켜주는 작업 (zero the parameter gradients)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = myNN(images)\n",
    "        loss = criterion(outputs, labels) # 뉴럴넷을 통과해서 나온 값을 실제 레이블과 비교하여 loss를 계산해야 함. 여기서는 8개 이미지에 대한 하나의 LOSS값을 얻게됨\n",
    "        loss.backward() # 위해서 구해진 loss값으로 weight를 수정하기 위해 backpropagation을 함\n",
    "        optimizer.step() # 옵티마이저의 설정값에 따라 그에 상응하는 크기로 weight를 수정함\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() # loss는 scalar형의 단일 숫자값으로 나오기 때문에 거기서 값만 딱 빼내기 위해서 item()함수를 체이닝 했다.\n",
    "        if i % 200 == 199: # batch 2000번 돌때마다 loss값이 어떻게 변하고 있는지 출력하겠다는 뜻\n",
    "            print(f\"[epoch: {epoch + 1}, batch: {i + 1:5d} loss: {running_loss / 2000:.3f}]\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print(\"학습 완료\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468b738-97de-41e0-b6f3-1076d32018de",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8da31ce0-d676-440e-b653-f58df68409df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(myNN.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b58404-8164-4744-ab4c-2c6da6ac7c26",
   "metadata": {},
   "source": [
    "모델을 저장하는 것은 반드시 모든 epoch이 끝나고 할 필요는 없다. 무조건 많은 epoch을 돈다고 해서 좋은 모델이 나오는 것이 아니다.\n",
    "학습을 하는 도중에 best model이 나왔을 수도 있다. 바로 그 순간 model을 저장하도록 구성할 수 있다. \n",
    "그렇게 하려면 이렇게 모델을 save하는 코드를 위에서 모델을 trainning하는 코드 중간에 넣으면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec8620-b7f1-49ef-98cf-2fc79225e24f",
   "metadata": {},
   "source": [
    "# Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "964cc2e5-61c0-411d-9980-186ab97749ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptNN = kenGwonNeuralNet()\n",
    "ptNN.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de456019-efbf-4bbc-b125-588cdbef03e0",
   "metadata": {},
   "source": [
    "#### output은 mini batch의 결과가 산출되기 때문에 for문을 통해서 test 전체의 예측값을 구해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02e42c62-03ef-411f-a705-ba03cc185c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000개의 테스트 이미지에 대한 정확도: 52.79 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # 실제로 test data에 대해서 예측을 할 때는 gradient를 업데이트 하면 안되기 때문에 반드시 이 구문으로 감싸주고 테스트 데이터를 돌려봐야 한다.\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = ptNN(images) # 우리가 만든 뉴럴넷의 최종 레이어는 output으로 10개의 값을 리턴하도록 되어있다.\n",
    "        _, predicted = torch.max(outputs.data, 1) # 그 10개의 값들 중에서 가장 값이 큰 것이 그 클래스일 확률이 높다는 것으로 보는 것이다. np.argmax같은 것이다.\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'1000개의 테스트 이미지에 대한 정확도: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e50c42-e6fb-4920-9e1e-207acc98e40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
