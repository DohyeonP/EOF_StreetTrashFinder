{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7897f9-744a-4878-b19a-2bb25f29ad58",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27691cb2-2964-4453-9ad5-3076b0b1a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler # learning rate를 학습 중간중간에 바꿀 수 있게 해주는 함수\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc0128-0573-4b55-9cb0-18204804647a",
   "metadata": {},
   "source": [
    "# 모델 형태 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b201d9-83be-4981-870c-6702d6a15589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kengwon/ken/EOF_SeparateTrashCollection/ArtificialNeuralNetwork/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(weights=True)\n",
    "num_features = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_features, 2) \n",
    "# 위의 코드를 보면 마지막 레이어의 상태가 (fc): Linear(in_features=512, out_features=1000, bias=True) 였는데, \n",
    "# 이걸 (fc): Linear(in_features=512, out_features=2, bias=True) 로 바꿔준 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c8d45-f6f6-4ecd-a666-66cce64dbbab",
   "metadata": {},
   "source": [
    "# 모델 파라미터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1dcc233-c02e-46c1-8369-9a70c72221f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './eof_bottle_classification_model.pth'\n",
    "model_ft.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b9e39-35a2-48fe-94fb-e939507e169a",
   "metadata": {},
   "source": [
    "# 모델이 원하는 인풋 형상으로 변환시켜주기 위한 transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e99d66-1d2e-4952-973c-76d5cb193487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 학습시킨 모델이 원하는 인풋 현상\n",
    "test_data_transforms = transforms.Compose([transforms.ToPILImage(), ## opencv로 이미지 읽어서 돌릴꺼면 pil 이미지로 한번 변환해줘야함\n",
    "                                         transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(), \n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57f56d-9c27-484e-8476-559ef6dd9e09",
   "metadata": {},
   "source": [
    "# inputs 이미지 로드 (openCV 이미지 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2504a61a-882f-4ce1-b12e-40fdb608be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(\"test_input4.jpg\")\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "test_tensor = test_data_transforms(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48bccc0-42f5-4506-84a6-26746a8e7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()\n",
    "with torch.no_grad():\n",
    "    # test_tensor = test_tensor.to(device)\n",
    "    outputs = model_ft(test_tensor.unsqueeze(0)) # 모델은 현재 batch 디멘션이 포함된 4D 형태의 인풋을 기대하고 있음\n",
    "    _, predicts = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84bf39b-832a-4a23-8bb0-8edd065a6723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7508])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1302a7e-ee78-41f4-9faf-3daafb199a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yl_bottle'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['nl_bottle', 'yl_bottle']\n",
    "class_names[predicts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c1f0a-4ccc-40b6-9cfc-2b06373825b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
